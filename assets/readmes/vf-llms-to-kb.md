# LLMS.txt to Voiceflow Knowledge Base

A CLI and API to upload markdown formatted docs from a llms.txt like the one generated by [README.com](https://readme.com) to a Voiceflow Knowledge Base, with one-way sync support.

## Features
- Parse URL to a llms.txt to extract markdown doc links
- Fetch and upload docs to a Voiceflow KB
- Avoids re-uploading unchanged docs (local hash db)
- CLI and REST API interface
- Task status tracking
- **One-way sync:** Remove docs from KB that are no longer in llms.txt
- Force upload/update all docs with `--force` or `force: true`
- **Multi-tenant support:** Use the `DOMAIN` env variable to target different Voiceflow environments (e.g., `voiceflow.com`, `cloud.voiceflow.com`)

## Setup

1. Clone the repo
2. Install dependencies:
   ```sh
   npm install
   ```
3. Copy the environment template and fill in your values:
   ```sh
   cp .env.template .env
   # Then edit .env and set your API_KEY, LLMS_URL, DOMAIN, and PORT as needed
   # For Docker/cloud, set SQLITE_PATH to a writable location (e.g., /tmp/vfllms.db)
   ```
4. Build the project:
   ```sh
   npm run build
   ```

## Docker & Docker Compose

You can run the API and CLI in a containerized environment with persistent storage for the local database (`vfllms.db`).

### Build and Run with Docker Compose

```sh
docker compose up --build
```
This will start the API server on the port specified by the `PORT` variable (default 3000) and mount `vfllms.db` for persistence.

**To run the API in the background (detached mode):**
```sh
docker compose up --build -d
```

**To view real-time logs from the running container:**
```sh
docker compose logs -f
```
This will show you live logs from the API server (including progress and status updates for API-triggered jobs).

**If you make changes to the code, use the following to ensure a fresh build:**
```sh
docker compose build --no-cache
```

**Port Mapping:**
- The `PORT` variable in your `.env` controls both the host and container port.
- For example, if you set `PORT=8080`, the API will be available at `http://localhost:8080`.

### Run CLI Commands in the Container

You can run CLI commands inside the running container:

```sh
docker compose exec vf-llms-to-kb npm run cli -- upload --force --sync
```

Or, for a one-off CLI run (without starting the API):

```sh
docker compose run --rm vf-llms-to-kb npm run cli -- upload --sync
```

### Stopping and Cleaning Up

To stop the container:
```sh
docker compose down
```

The `vfllms.db` file will persist in your project directory.

## API Domain Configuration

The API base URL is determined by the `DOMAIN` environment variable:
- If `DOMAIN=voiceflow.com` (default):
  - Uploads and sync use `https://api.voiceflow.com/...`
- If `DOMAIN=cloud.voiceflow.com`:
  - Uploads and sync use `https://api.cloud.voiceflow.com/...`

This allows you to target different Voiceflow environments or tenants.

## CLI Usage

### Upload docs
```sh
npm run cli -- upload --api-key <API_KEY> --llms-url <LLMS_URL>
```
If no API key or llms.txt URL is provided, values from `.env` are used.

### Force upload all docs (ignore hash)
```sh
npm run cli -- upload --force
```

### Upload and sync (remove stale docs from KB)
```sh
npm run cli -- upload --sync
```

### Upload, force update, and sync in one shot
```sh
npm run cli -- upload --force --sync
```

## API Usage

Start the server:
```sh
npm start
```

### Health Check

Check if the API is running and healthy:
```sh
curl http://localhost:3000/health
```
Returns:
```json
{ "status": "ok" }
```

### POST /upload

**Request:**
```sh
curl -X POST http://localhost:3000/upload \
  -H "Content-Type: application/json" \
  -d '{
    "apiKey": "YOUR_API_KEY",
    "llmsUrl": "https://your-llms-txt-url",
    "force": false,
    "sync": true
  }'
```

**Request body:**
```json
{
  "apiKey": "...",         // optional if in .env
  "llmsUrl": "...",        // optional if in .env
  "force": false,           // optional, force upload all docs
  "sync": false             // optional, remove docs from KB not in llms.txt
}
```

**Response:**
```json
{ "taskId": "e3b0c442-98fc-4b2e-8c2e-7b8e1e2e3b0c" }
```

### GET /status/:taskId

**Request:**
```sh
curl http://localhost:3000/status/e3b0c442-98fc-4b2e-8c2e-7b8e1e2e3b0c
```

**Response example:**
```json
{
  "id": "e3b0c442-98fc-4b2e-8c2e-7b8e1e2e3b0c",
  "status": "done",
  "progress": 100,
  "message": "Done",
  "startedAt": 1717690000000,
  "finishedAt": 1717690020000
}
```

### Change the API Server Port

By default, the server runs on port 3000. To change the port, set the `PORT` environment variable in your `.env` file:
```env
PORT=8080
```
This will also change the port mapping in Docker Compose.

## One-way Sync Behavior
- When `--sync` or `sync: true` is used, any doc previously uploaded (tracked in the local DB) but no longer present in llms.txt will be deleted from the Voiceflow KB and removed from the local DB.
- Docs are matched by their source URL and tracked by their Voiceflow `documentID`.

## Local Database
- Uses SQLite (via better-sqlite3) to track doc hashes and Voiceflow documentIDs.
- Ensures efficient incremental uploads and safe deletion during sync.

## License
MIT


[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=voiceflow-community_vf-llms-to-kb&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=voiceflow-community_vf-llms-to-kb)
